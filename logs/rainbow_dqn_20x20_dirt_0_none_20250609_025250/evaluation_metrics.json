{
  "episode_rewards": [
    -67.04499999999979,
    -30.925000000000313,
    -95.67800000000013,
    -69.52499999999993,
    -29.626999999999967
  ],
  "episode_lengths": [
    541,
    1277,
    215,
    197,
    455
  ],
  "coverage_ratio": [
    0.1575,
    0.625,
    0.08,
    0.1075,
    0.19
  ],
  "path_efficiency": [
    1.355,
    3.195,
    0.54,
    0.495,
    1.14
  ],
  "revisit_ratio": [
    159.43542435424354,
    30.7339593114241,
    435.2962962962963,
    460.55555555555554,
    182.01754385964912
  ],
  "cleaning_time": [],
  "action_distributions": [
    [
      0.3345656192236599,
      0.4011090573012939,
      0.2643253234750462
    ],
    [
      0.4659357870007831,
      0.3288958496476116,
      0.20516836335160532
    ],
    [
      0.8511627906976744,
      0.11162790697674418,
      0.037209302325581395
    ],
    [
      0.8730964467005076,
      0.08629441624365482,
      0.04060913705583756
    ],
    [
      0.5560439560439561,
      0.2857142857142857,
      0.15824175824175823
    ]
  ],
  "episodes_detail": [
    {
      "episode": 1,
      "steps": 541,
      "total_reward": -67.04499999999979,
      "action_distribution": {
        "forward": 0.3345656192236599,
        "left": 0.4011090573012939,
        "right": 0.2643253234750462
      },
      "coverage_ratio": 0.1575,
      "path_efficiency": 1.355,
      "revisit_ratio": 159.43542435424354
    },
    {
      "episode": 2,
      "steps": 1277,
      "total_reward": -30.925000000000313,
      "action_distribution": {
        "forward": 0.4659357870007831,
        "left": 0.3288958496476116,
        "right": 0.20516836335160532
      },
      "coverage_ratio": 0.625,
      "path_efficiency": 3.195,
      "revisit_ratio": 30.7339593114241
    },
    {
      "episode": 3,
      "steps": 215,
      "total_reward": -95.67800000000013,
      "action_distribution": {
        "forward": 0.8511627906976744,
        "left": 0.11162790697674418,
        "right": 0.037209302325581395
      },
      "coverage_ratio": 0.08,
      "path_efficiency": 0.54,
      "revisit_ratio": 435.2962962962963
    },
    {
      "episode": 4,
      "steps": 197,
      "total_reward": -69.52499999999993,
      "action_distribution": {
        "forward": 0.8730964467005076,
        "left": 0.08629441624365482,
        "right": 0.04060913705583756
      },
      "coverage_ratio": 0.1075,
      "path_efficiency": 0.495,
      "revisit_ratio": 460.55555555555554
    },
    {
      "episode": 5,
      "steps": 455,
      "total_reward": -29.626999999999967,
      "action_distribution": {
        "forward": 0.5560439560439561,
        "left": 0.2857142857142857,
        "right": 0.15824175824175823
      },
      "coverage_ratio": 0.19,
      "path_efficiency": 1.14,
      "revisit_ratio": 182.01754385964912
    }
  ]
}