{
    "raw_metrics": {
        "episode_rewards": [
            -18.28999971747366,
            -45.10000000000071,
            -431497.31999992335,
            -39.859999942779666,
            -35.0999999999998,
            -46.10000000000083,
            -441849.20000000205,
            -28.099999999999536,
            -49.10000000000117,
            -41.10000000000024,
            -49.10000000000117,
            -39.100000000000094,
            -446309.10000000213,
            -28.259999942779153,
            -49.10000000000117,
            -43.629999989271695,
            -424741.1799998303,
            -421565.0599998732,
            -438880.069999977,
            -45.10000000000071
        ],
        "episode_lengths": [
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000,
            3000
        ],
        "coverage_ratio": [
            0.02040816326530612,
            0.024390243902439025,
            0.07317073170731707,
            0.07317073170731707,
            0.2413793103448276,
            0.09090909090909091,
            0.014492753623188406,
            0.09090909090909091,
            0.01639344262295082,
            0.022222222222222223,
            0.012345679012345678,
            0.01639344262295082,
            0.024390243902439025,
            0.2413793103448276,
            0.02040816326530612,
            0.05405405405405406,
            0.2413793103448276,
            0.1111111111111111,
            0.024390243902439025,
            0.030303030303030304
        ],
        "path_efficiency": [
            2.2953549517966696,
            2.2973684210526315,
            0.04203152364273205,
            2.2953549517966696,
            2.2973684210526315,
            2.2953549517966696,
            0.02276707530647986,
            2.2953549517966696,
            2.299385425812116,
            2.299385425812116,
            2.2953549517966696,
            2.2953549517966696,
            0.010517090271691499,
            2.2936021034180545,
            2.2953549517966696,
            2.307894736842105,
            0.06923751095530237,
            0.06654991243432574,
            0.027192982456140352,
            2.2973684210526315
        ],
        "revisit_ratio": [
            0.9694539900725467,
            0.9694539900725467,
            0.020833333333333332,
            0.9644902634593356,
            0.9694539900725467,
            0.9694539900725467,
            0.0,
            0.9694539900725467,
            0.9694539900725467,
            0.9694539900725467,
            0.9694539900725467,
            0.9694539900725467,
            0.0,
            0.9644631257164692,
            0.9694539900725467,
            0.9688331432915241,
            0.02531645569620253,
            0.02631578947368421,
            0.16129032258064516,
            0.9694539900725467
        ],
        "cleaning_time": []
    },
    "summary_statistics": {
        "episode_rewards": {
            "mean": -130269.9375,
            "std": 198990.578125
        },
        "episode_lengths": {
            "mean": 3000.0,
            "std": 0.0
        },
        "coverage_ratio": {
            "mean": 0.07218001782894135,
            "std": 0.07682019472122192
        },
        "path_efficiency": {
            "mean": 1.6199076175689697,
            "std": 1.0345520973205566
        },
        "revisit_ratio": {
            "mean": 0.6897767782211304,
            "std": 0.427156925201416
        },
        "cleaning_time": {
            "mean": 0.0,
            "std": 0.0
        }
    }
}